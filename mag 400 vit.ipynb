{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ba78ac0-7413-43f2-9f19-357612db62d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AMLAN\\anaconda3\\envs\\tf2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AMLAN\\anaconda3\\envs\\tf2\\lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\AMLAN\\anaconda3\\envs\\tf2\\lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\AMLAN\\AppData\\Local\\Temp\\ipykernel_7480\\1690989922.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='365' max='365' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [365/365 05:13, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.356116</td>\n",
       "      <td>0.876336</td>\n",
       "      <td>0.907990</td>\n",
       "      <td>0.897129</td>\n",
       "      <td>0.902527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.437544</td>\n",
       "      <td>0.871756</td>\n",
       "      <td>0.907317</td>\n",
       "      <td>0.889952</td>\n",
       "      <td>0.898551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.644361</td>\n",
       "      <td>0.836641</td>\n",
       "      <td>0.830149</td>\n",
       "      <td>0.935407</td>\n",
       "      <td>0.879640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.515774</td>\n",
       "      <td>0.883969</td>\n",
       "      <td>0.919118</td>\n",
       "      <td>0.897129</td>\n",
       "      <td>0.907990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.523825</td>\n",
       "      <td>0.883969</td>\n",
       "      <td>0.911058</td>\n",
       "      <td>0.906699</td>\n",
       "      <td>0.908873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Evaluation Metrics: {'eval_loss': 0.3560798466205597, 'eval_accuracy': 0.8763358778625954, 'eval_precision': 0.9079903147699758, 'eval_recall': 0.8971291866028708, 'eval_f1': 0.9025270758122743, 'eval_runtime': 19.2367, 'eval_samples_per_second': 34.049, 'eval_steps_per_second': 2.131, 'epoch': 5.0}\n",
      "Prediction for random test image: Benign\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor, TrainingArguments, Trainer\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# -------- Step 1: Load Dataset --------\n",
    "class BreastCancerDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Read all images and assign labels based on filenames\n",
    "        for img_name in os.listdir(root_dir):\n",
    "            if img_name.endswith(\".png\"):\n",
    "                self.image_paths.append(os.path.join(root_dir, img_name))\n",
    "                self.labels.append(0 if \"SOB_B\" in img_name else 1)  # 0=Benign, 1=Malignant\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return {\"pixel_values\": image, \"labels\": torch.tensor(label)}\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = BreastCancerDataset(r\"D:\\01 STUDY MATERIAL\\ai project\\mkfold\\combined fold 1\\train_400x\", transform=transform)\n",
    "test_dataset = BreastCancerDataset(r\"D:\\01 STUDY MATERIAL\\ai project\\mkfold\\combined fold 1\\test_400x\", transform=transform)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Load ViT feature extractor\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "# -------- Step 2: Define ViT Model --------\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224-in21k\",\n",
    "    num_labels=2,  # Binary classification\n",
    "    id2label={0: \"Benign\", 1: \"Malignant\"},\n",
    "    label2id={\"Benign\": 0, \"Malignant\": 1},\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# -------- Step 3: Define Evaluation Metrics --------\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision = precision_score(labels, predictions)\n",
    "    recall = recall_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions)\n",
    "    \n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "# -------- Step 4: Define Training Arguments --------\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./vit_cancer_detection\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    fp16=True,  # Mixed precision training\n",
    ")\n",
    "\n",
    "# -------- Step 5: Train Model --------\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# -------- Step 6: Save Model --------\n",
    "trainer.save_model(\"vit_binary_model_400x\")\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# -------- Step 7: Load Best Model and Evaluate --------\n",
    "model = ViTForImageClassification.from_pretrained(\"vit_binary_model_400X\")\n",
    "model.to(device)\n",
    "\n",
    "trainer.model = model\n",
    "metrics = trainer.evaluate()\n",
    "print(\"Final Evaluation Metrics:\", metrics)\n",
    "\n",
    "# -------- Step 8: Make Predictions on Random Image --------\n",
    "import random\n",
    "import os\n",
    "\n",
    "def predict_random_image(test_dir):\n",
    "    random_class = random.choice(['benign', 'malignant'])\n",
    "    random_image = random.choice(os.listdir(os.path.join(test_dir, random_class)))\n",
    "    image_path = os.path.join(test_dir, random_class, random_image)\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = feature_extractor(image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "    return \"Benign\" if predicted_class == 0 else \"Malignant\"\n",
    "\n",
    "# Example prediction\n",
    "test_dir = 'D:/01 STUDY MATERIAL/ai project/Breast-Splitted/test'\n",
    "print(\"Prediction for random test image:\", predict_random_image(test_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d189ba-edb0-4a51-b45f-be3f7ab8e7c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
